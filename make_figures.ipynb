{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8627d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from models import SingleEncoderModel, DualEncoderModel\n",
    "from data_utils import HM_Dataset\n",
    "from generate_utils import load_DE, load_SE, nucleus_token_by_token_generate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plot_utils import save_attention_maps_with_split, save_attention_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7fd5d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvis = None\n",
    "subfolder = 'T2_M2'\n",
    "# subfolder = 'T10_M2'\n",
    "# subfolder = 'T2_M10'\n",
    "# subfolder = 'T10_M10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "587de86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = HM_Dataset(\"data/test_\" + subfolder + \".pkl\")\n",
    "d = test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71afabd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_path:  saved_models/SE/T2_M2.pt\n"
     ]
    }
   ],
   "source": [
    "unmasking_order = 'start' # in ['random', 'start', 'end', 'certain', 'uncertain']\n",
    "\n",
    "device_name = 'cpu'\n",
    "model = load_SE(\n",
    "    test_dataset.m_vocab_size,\n",
    "    test_dataset.h_vocab_size,\n",
    "    test_dataset.seq_len,\n",
    "    subfolder=subfolder,\n",
    "    device_name=device_name,\n",
    "    nvis=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbfca772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281633\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "278244d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['m_seq'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a6c58b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_tokens = nucleus_token_by_token_generate(\n",
    "    model,\n",
    "    d['m_seq'],\n",
    "    test_dataset.mask_token_id,\n",
    "    temperature=0.5,\n",
    "    p=0.9,\n",
    "    unmasking_order='start'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82f52d48",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SingleEncoderModel' object has no attribute 'get_attention_maps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# After running a forward pass with attention outputs enabled\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# attn_maps = model.harmony_encoder.layers[4].last_attn_weights  # example shape: [B, heads, L, L]\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m self_attns \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_attention_maps\u001b[49m()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Focus on one item in batch, one head\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mmap\u001b[39m \u001b[38;5;241m=\u001b[39m self_attns[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SingleEncoderModel' object has no attribute 'get_attention_maps'"
     ]
    }
   ],
   "source": [
    "# After running a forward pass with attention outputs enabled\n",
    "# attn_maps = model.harmony_encoder.layers[4].last_attn_weights  # example shape: [B, heads, L, L]\n",
    "self_attns = model.get_attention_maps()\n",
    "\n",
    "# Focus on one item in batch, one head\n",
    "map = self_attns[0][0, 0].detach().cpu().numpy()\n",
    "sns.heatmap(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eba28d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir='figs/attn_maps/' + subfolder\n",
    "if nvis is not None:\n",
    "    save_dir += '_nvis' + str(nvis)\n",
    "\n",
    "save_attention_maps_with_split(\n",
    "    self_attns,\n",
    "    melody_len=test_dataset.seq_len,\n",
    "    save_dir=save_dir + '/self/',\n",
    "    prefix='self'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
